{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**\n",
        "\n",
        "В PySpark приложении датафреймами(pyspark.sql.DataFrame) заданы продукты, категории и их связи. Каждому продукту может соответствовать несколько категорий или ни одной. А каждой категории может соответствовать несколько продуктов или ни одного. Напишите метод на PySpark, который в одном датафрейме вернет все пары «Имя продукта – Имя категории» и имена всех продуктов, у которых нет категорий."
      ],
      "metadata": {
        "id": "VvCxNfXUhFG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K7Ags1yfXT-",
        "outputId": "0beb476a-4b50-4ac7-8529-0f25d725d09a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=ca47b4e6cb64d91a51bea8a0b432ff5c5228af6c3217315e90dc2acd513e398a\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Iiz0jN3OfB8G"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_pyspark = SparkSession.builder.appName(\"ProductCategoryPairs\").getOrCreate()"
      ],
      "metadata": {
        "id": "-9PRppddfH3V"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products = [\n",
        "    (\"Продукт 1\", \"1\"),\n",
        "    (\"Продукт 2\", \"1\"),\n",
        "    (\"Продукт 3\", None),\n",
        "    (\"Продукт 4\", \"2\"),\n",
        "    (\"Продукт 5\", None),\n",
        "]\n",
        "\n",
        "categories = [\n",
        "    (\"1\", \"Категория 1\"),\n",
        "    (\"2\", \"Категория 2\"),\n",
        "    (\"3\", \"Категория 3\"),\n",
        "]"
      ],
      "metadata": {
        "id": "U01WebHqfsRd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создаем исходные датафреймы\n",
        "products_df = my_pyspark.createDataFrame(products, [\"product\", \"category\"])\n",
        "categories_df = my_pyspark.createDataFrame(categories, [\"category\", \"category_name\"])"
      ],
      "metadata": {
        "id": "f_CtAmxDfxE9"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# объединяем данные\n",
        "joined_df = products_df.join(categories_df, on=\"category\", how=\"left\")"
      ],
      "metadata": {
        "id": "FL2OKQ2uf0Lq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# фильтруем\n",
        "products_without_category_df = joined_df.filter(col(\"category\").isNull())"
      ],
      "metadata": {
        "id": "UwBnLasVf3yD"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# формируем результирующий датафрейм\n",
        "result_df = joined_df.select(\n",
        "    col(\"product\").alias(\"Имя продукта\"),\n",
        "    when(col(\"category_name\").isNull(), \"Нет категории\").otherwise(col(\"category_name\")).alias(\"Имя категории\")\n",
        ").distinct()"
      ],
      "metadata": {
        "id": "rG-wbLi4f8ar"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g67zB-wMf-N_",
        "outputId": "f39f22b1-698a-46fb-abc3-f59fe4719510"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------+\n",
            "|Имя продукта|Имя категории|\n",
            "+------------+-------------+\n",
            "|Продукт 1   |Категория 1  |\n",
            "|Продукт 5   |Нет категории|\n",
            "|Продукт 4   |Категория 2  |\n",
            "|Продукт 2   |Категория 1  |\n",
            "|Продукт 3   |Нет категории|\n",
            "+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_pyspark.stop()"
      ],
      "metadata": {
        "id": "DXIp6AVZgQTM"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}